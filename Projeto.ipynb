{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projeto C318 - Detecção de Fraudes em Cartões Bancários\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilização do Isolation Forest Para isolar as Possíveis Anomalias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cinqu\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão somente com o Isolation Forest: 0.07\n",
      "Revocação somente com o Isolation Forest: 0.85\n",
      "Precisão após classificador supervisionado: 0.95\n",
      "Revocação após classificador supervisionado: 0.91\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Carregar o conjunto de dados\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# Selecionar as colunas de features e a coluna de classe\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Aplicar PCA para reduzir para 20 componentes principais\n",
    "pca = PCA(n_components=20)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Etapa 1: Detecção de anomalias com Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.02, random_state=42)\n",
    "anomaly_labels = iso_forest.fit_predict(X_pca)\n",
    "\n",
    "# Adicionar os rótulos de anomalia ao dataframe original\n",
    "df['anomaly'] = anomaly_labels\n",
    "\n",
    "# Selecionar apenas os outliers detectados (anomaly == -1)\n",
    "outliers = df[df['anomaly'] == -1]\n",
    "X_outliers = outliers.drop(columns=['Class', 'anomaly'])\n",
    "y_outliers = outliers['Class']  # Classes reais dos outliers\n",
    "\n",
    "# Calcular Precisão e Revocação\n",
    "TP = ((df['anomaly'] == -1) & (df['Class'] == 1)).sum()   # Verdadeiros Positivos\n",
    "FP = ((df['anomaly'] == -1) & (df['Class'] == 0)).sum()   # Falsos Positivos\n",
    "FN = ((df['anomaly'] == 1) & (df['Class'] == 1)).sum()  # Falsos Negativos\n",
    "\n",
    "precisionISO = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recallISO = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "print(f\"Precisão somente com o Isolation Forest: {precisionISO:.2f}\")\n",
    "print(f\"Revocação somente com o Isolation Forest: {recallISO:.2f}\")\n",
    "\n",
    "# Etapa 2: Treinamento do Classificador Supervisionado\n",
    "# Dividir os dados de outliers em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_outliers, y_outliers, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinar um classificador supervisionado (Random Forest)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calcular métricas de avaliação\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Precisão após classificador supervisionado: {precision:.2f}\")\n",
    "print(f\"Revocação após classificador supervisionado: {recall:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
